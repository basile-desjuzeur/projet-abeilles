{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <u>**Resnet 50 avec politique de batch uniformément réparti** </u></center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:08:04.536855: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-04 10:08:04.894579: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main folder\n",
    "path_to_folder = '../data_bees_detection/dataset_classification'\n",
    "\n",
    "classes = os.listdir(os.path.join(path_to_folder, 'train'))\n",
    "nb_classes = len(classes)  \n",
    "\n",
    "# function to load a split of the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    target_files = np.array(data['filenames'])\n",
    "    target_labels = keras.utils.to_categorical(np.array(data['target']), nb_classes)\n",
    "    return target_files, target_labels\n",
    "\n",
    "# load the datasets\n",
    "train_files, train_labels = load_dataset(os.path.join(path_to_folder, 'train'))\n",
    "valid_files, valid_labels = load_dataset(os.path.join(path_to_folder, 'validation'))\n",
    "test_files, test_labels = load_dataset(os.path.join(path_to_folder, 'test'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de l'augmentation et de la normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to augment the images\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations import (Compose, Rotate, HorizontalFlip, VerticalFlip, Affine, RandomBrightnessContrast, ChannelShuffle)\n",
    "import albumentations as A\n",
    "\n",
    "AUGMENTATIONS = Compose([\n",
    "    Rotate(limit=[0,100], p=0.5),\n",
    "    HorizontalFlip(p=0.5),\n",
    "    VerticalFlip(p=0.5),\n",
    "    Affine(shear=[-45, 45], p=0.5),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return preprocess_input(np.expand_dims(x, axis=0))\n",
    "\n",
    "class BatchGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, paths, labels, batch_size, augmentations,normalize=None):\n",
    "\n",
    "\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "        self.normalize = normalize\n",
    "      \n",
    "        self.num_classes = np.unique(self.labels).shape[0]\n",
    "        self.min_class_count = min(np.unique(self.labels, return_counts=True)[1])\n",
    "\n",
    "\n",
    "        # get class indices\n",
    "        class_indices = []\n",
    "        for i in range(self.num_classes):\n",
    "            class_indices.append(np.where(self.labels == i)[0])\n",
    "        self.class_indices = class_indices\n",
    "\n",
    "        # shuffle indices at the beginning of first epoch\n",
    "        self.on_epoch_end()\n",
    "\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # nb of batches per epoch\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def load_img(self, img_path):\n",
    "\n",
    "        # loads img \n",
    "        img = load_img(img_path, target_size=(224,224))\n",
    "        x = img_to_array(img)\n",
    "        \n",
    "        # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "        x =  np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        return x\n",
    "\n",
    "    def apply_augmentation(self, batch_imgs):\n",
    "        # apply augmentation to a batch of images\n",
    "\n",
    "        batch_imgs = batch_imgs.astype(np.uint8)\n",
    "        \n",
    "\n",
    "        for i in range(len(batch_imgs)):\n",
    "            batch_imgs[i] = self.augment(image=batch_imgs[i])['image']\n",
    "\n",
    "        return batch_imgs\n",
    "    \n",
    "    def normalize_batch(self, batch_imgs):\n",
    "        # normalize a batch of images\n",
    "\n",
    "        batch_imgs = batch_imgs.astype(np.float32)\n",
    "\n",
    "        # normalize with imagenet stats\n",
    "        mean = [125.3, 123.0, 113.9]\n",
    "        std  = [63.0,  62.1,  66.7]\n",
    "\n",
    "        for i in range(len(batch_imgs)):\n",
    "            batch_imgs[i] -= mean\n",
    "            batch_imgs[i] /= std\n",
    "\n",
    "        return batch_imgs\n",
    "        \n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get batch at position index\n",
    "\n",
    "        indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_paths = self.paths[indices]\n",
    "        batch_labels = self.labels[indices]\n",
    "\n",
    "        batch_imgs = np.zeros((len(batch_paths), 224, 224, 3))\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            batch_imgs[i] = self.load_img(f)\n",
    "\n",
    "        if self.augment: \n",
    "            batch_imgs = self.apply_augmentation(batch_imgs)\n",
    "\n",
    "        if self.normalize:\n",
    "            batch_imgs = self.normalize_batch(batch_imgs)\n",
    "            \n",
    "        return batch_imgs, batch_labels\n",
    "    \n",
    "\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "\n",
    "        balanced_indices = []\n",
    "\n",
    "        for indices in self.class_indices:\n",
    "            if len(indices) > self.min_class_count:\n",
    "                indices = np.random.choice(indices, size=self.min_class_count, replace=True)\n",
    "            balanced_indices.extend(indices)\n",
    "\n",
    "        self.indices = np.array(balanced_indices)\n",
    "\n",
    "        print(self.indices)\n",
    "\n",
    "        np.random.shuffle(self.indices)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41280 32723 19038 ... 59442 59443 59444]\n",
      "[12174  7051 10644 ... 15323 15324 15325]\n",
      "[ 7975  7296   542 ... 19114 19115 19116]\n"
     ]
    }
   ],
   "source": [
    "ds_train = BatchGenerator(train_files, train_labels, 16, False,False)\n",
    "ds_valid = BatchGenerator(valid_files, valid_labels, 16,  False,False)\n",
    "ds_test = BatchGenerator(test_files, test_labels, 16,  False,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choix de l'architecture du modèle, des paramètres et hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:08:48.248055: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:48.283958: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:48.284761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:48.290520: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:48.291283: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:48.291765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:49.589343: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:49.589985: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:49.590365: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-04 10:08:49.590675: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2594 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "# we take resnet50 as convolutional base with weights trained on imagenet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# we add the classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# we create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opti = Adam(learning_rate=0.0001)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# checkpoint to save the best model\n",
    "path_to_weights = '/datafiles/classification/saved_weights/benchmark_weights/3_resnet_batch_capped.h5'\n",
    "checkpoint = ModelCheckpoint(filepath=path_to_weights, monitor='val_categorical_accuracy', save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=10)\n",
    "\n",
    "# reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(path_to_weights)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entrainement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:08:54.856833: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-04 10:09:06.072993: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-04 10:09:09.032009: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.423840: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.423954: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.465431: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.465530: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.607284: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.607390: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.685364: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.685466: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-07-04 10:09:09.722418: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3716/3716 [==============================] - ETA: 0s - loss: 0.2445 - categorical_accuracy: 0.9266 - precision: 0.9483 - recall: 0.9086"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-04 10:29:54.097731: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1494  7427  8205 ... 15323 15324 15325]\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(ds_train, epochs=100, validation_data=ds_valid, callbacks=[checkpoint, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

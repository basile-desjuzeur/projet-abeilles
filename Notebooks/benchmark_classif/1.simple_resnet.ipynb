{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <u>**Premier réseau de classification : Resnet 50 , simple** </u></center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import des données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 02:59:58.567263: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-11 02:59:58.807030: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main folder\n",
    "path_to_folder = '../data_bees_detection/dataset_classification'\n",
    "\n",
    "classes = os.listdir(os.path.join(path_to_folder, 'train'))\n",
    "nb_classes = len(classes)  \n",
    "\n",
    "# function to load a split of the dataset\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    target_files = np.array(data['filenames'])\n",
    "    target_labels = keras.utils.to_categorical(np.array(data['target']), nb_classes)\n",
    "    return target_files, target_labels\n",
    "\n",
    "# load the datasets\n",
    "train_files, train_labels = load_dataset(os.path.join(path_to_folder, 'train'))\n",
    "valid_files, valid_labels = load_dataset(os.path.join(path_to_folder, 'validation'))\n",
    "test_files, test_labels = load_dataset(os.path.join(path_to_folder, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch generator\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.utils import Sequence\n",
    "from keras.utils import load_img, img_to_array\n",
    "\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return preprocess_input(np.expand_dims(x, axis=0))\n",
    "\n",
    "class BatchGenerator(Sequence):\n",
    "\n",
    "    def __init__(self, paths, labels, batch_size, augmentations):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.augment = augmentations\n",
    "\n",
    "    def __len__(self):\n",
    "        # nb of batches per epoch\n",
    "        return int(np.ceil(len(self.paths) / float(self.batch_size)))\n",
    "    \n",
    "    def load_img(self, img_path):\n",
    "\n",
    "        # loads img \n",
    "        img = load_img(img_path, target_size=(224,224))\n",
    "        x = img_to_array(img)\n",
    "        \n",
    "        # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "        x =  np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get batch at position index\n",
    "\n",
    "        batch_paths = self.paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_labels = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        batch_imgs = np.zeros((len(batch_paths), 224, 224, 3))\n",
    "        for i, f in enumerate(batch_paths):\n",
    "            batch_imgs[i] = self.load_img(f)\n",
    "\n",
    "        return batch_imgs, batch_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = BatchGenerator(train_files, train_labels, 16, None)\n",
    "ds_valid = BatchGenerator(valid_files, valid_labels, 16, None)\n",
    "ds_test = BatchGenerator(test_files, test_labels, 16, None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Choix de l'architecture du modèle, des paramètres et hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-11 03:00:35.294682: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:35.310724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:35.310979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:35.313198: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:35.313576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:35.313755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:36.169176: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:36.169499: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:36.169600: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-11 03:00:36.169694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2594 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "# we take resnet50 as convolutional base with weights trained on imagenet\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# we add the classification layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(nb_classes, activation='softmax')(x)\n",
    "\n",
    "# we create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opti = Adam(learning_rate=0.0001)\n",
    "metrics = [tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "model.compile(optimizer=opti, loss='categorical_crossentropy', metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# checkpoint to save the best model\n",
    "path_to_weights = '/datafiles/classification/saved_weights/1.simple_resnet.h5'\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.hdf5', monitor='val_categorical_accuracy', save_best_only=True, save_weights_only=False)\n",
    "\n",
    "# early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=10)\n",
    "\n",
    "# reduce learning rate\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.1, patience=5, min_lr=0.00001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Entrainement du modèle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : poids saved in proper place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5648/3742308348.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(ds_train, epochs=100, validation_data=ds_valid, callbacks=[checkpoint, early_stopping, reduce_lr])\n",
      "2023-06-30 22:41:36.194379: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-30 22:41:40.552601: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-30 22:41:42.535615: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.748885: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.748942: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.789273: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.789330: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.34GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.923569: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:42.923625: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:43.008470: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:43.008526: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-06-30 22:41:43.047835: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3716/3716 [==============================] - ETA: 0s - loss: 3.2534 - categorical_accuracy: 0.2830 - precision: 0.6591 - recall: 0.1295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-30 23:04:15.199673: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3716/3716 [==============================] - 1471s 394ms/step - loss: 3.2534 - categorical_accuracy: 0.2830 - precision: 0.6591 - recall: 0.1295 - val_loss: 2.1893 - val_categorical_accuracy: 0.4693 - val_precision: 0.7355 - val_recall: 0.3088 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "3716/3716 [==============================] - 1450s 390ms/step - loss: 1.8882 - categorical_accuracy: 0.5212 - precision: 0.7671 - recall: 0.3734 - val_loss: 1.7139 - val_categorical_accuracy: 0.5656 - val_precision: 0.7638 - val_recall: 0.4556 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "3716/3716 [==============================] - 1443s 388ms/step - loss: 1.3029 - categorical_accuracy: 0.6478 - precision: 0.8244 - recall: 0.5377 - val_loss: 1.6464 - val_categorical_accuracy: 0.5810 - val_precision: 0.7565 - val_recall: 0.4897 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "3716/3716 [==============================] - 1443s 388ms/step - loss: 0.9373 - categorical_accuracy: 0.7373 - precision: 0.8610 - recall: 0.6537 - val_loss: 1.5072 - val_categorical_accuracy: 0.6250 - val_precision: 0.7688 - val_recall: 0.5570 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "3716/3716 [==============================] - 1441s 388ms/step - loss: 0.6931 - categorical_accuracy: 0.8007 - precision: 0.8901 - recall: 0.7382 - val_loss: 1.6471 - val_categorical_accuracy: 0.6176 - val_precision: 0.7411 - val_recall: 0.5589 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "3716/3716 [==============================] - 1442s 388ms/step - loss: 0.5299 - categorical_accuracy: 0.8434 - precision: 0.9081 - recall: 0.7959 - val_loss: 1.6856 - val_categorical_accuracy: 0.6278 - val_precision: 0.7325 - val_recall: 0.5842 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "3716/3716 [==============================] - 1441s 388ms/step - loss: 0.4239 - categorical_accuracy: 0.8724 - precision: 0.9212 - recall: 0.8354 - val_loss: 1.8009 - val_categorical_accuracy: 0.6148 - val_precision: 0.7186 - val_recall: 0.5760 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "3716/3716 [==============================] - 1439s 387ms/step - loss: 0.3508 - categorical_accuracy: 0.8915 - precision: 0.9300 - recall: 0.8626 - val_loss: 1.8152 - val_categorical_accuracy: 0.6237 - val_precision: 0.7115 - val_recall: 0.5908 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "3716/3716 [==============================] - 1438s 387ms/step - loss: 0.2946 - categorical_accuracy: 0.9090 - precision: 0.9395 - recall: 0.8850 - val_loss: 1.9298 - val_categorical_accuracy: 0.6194 - val_precision: 0.7023 - val_recall: 0.5904 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "3716/3716 [==============================] - 1438s 387ms/step - loss: 0.2607 - categorical_accuracy: 0.9200 - precision: 0.9450 - recall: 0.8994 - val_loss: 1.9519 - val_categorical_accuracy: 0.6227 - val_precision: 0.6988 - val_recall: 0.5944 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "3716/3716 [==============================] - 1438s 387ms/step - loss: 0.2273 - categorical_accuracy: 0.9295 - precision: 0.9494 - recall: 0.9120 - val_loss: 2.0094 - val_categorical_accuracy: 0.6221 - val_precision: 0.6937 - val_recall: 0.5972 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "3716/3716 [==============================] - 1438s 387ms/step - loss: 0.0723 - categorical_accuracy: 0.9794 - precision: 0.9844 - recall: 0.9732 - val_loss: 1.7240 - val_categorical_accuracy: 0.6860 - val_precision: 0.7412 - val_recall: 0.6684 - lr: 1.0000e-05\n",
      "Epoch 13/100\n",
      "3716/3716 [==============================] - 1438s 387ms/step - loss: 0.0211 - categorical_accuracy: 0.9953 - precision: 0.9963 - recall: 0.9936 - val_loss: 1.8579 - val_categorical_accuracy: 0.6921 - val_precision: 0.7375 - val_recall: 0.6777 - lr: 1.0000e-05\n",
      "Epoch 14/100\n",
      "3716/3716 [==============================] - 1435s 386ms/step - loss: 0.0111 - categorical_accuracy: 0.9976 - precision: 0.9979 - recall: 0.9970 - val_loss: 1.9585 - val_categorical_accuracy: 0.6914 - val_precision: 0.7338 - val_recall: 0.6794 - lr: 1.0000e-05\n",
      "Epoch 15/100\n",
      "3716/3716 [==============================] - 1435s 386ms/step - loss: 0.0080 - categorical_accuracy: 0.9982 - precision: 0.9984 - recall: 0.9979 - val_loss: 2.0419 - val_categorical_accuracy: 0.6917 - val_precision: 0.7285 - val_recall: 0.6808 - lr: 1.0000e-05\n",
      "Epoch 16/100\n",
      "3716/3716 [==============================] - 1437s 387ms/step - loss: 0.0053 - categorical_accuracy: 0.9989 - precision: 0.9990 - recall: 0.9988 - val_loss: 2.1442 - val_categorical_accuracy: 0.6923 - val_precision: 0.7253 - val_recall: 0.6833 - lr: 1.0000e-05\n",
      "Epoch 17/100\n",
      "3716/3716 [==============================] - 1435s 386ms/step - loss: 0.0048 - categorical_accuracy: 0.9990 - precision: 0.9991 - recall: 0.9988 - val_loss: 2.1497 - val_categorical_accuracy: 0.6931 - val_precision: 0.7254 - val_recall: 0.6843 - lr: 1.0000e-05\n",
      "Epoch 18/100\n",
      "3716/3716 [==============================] - 1436s 386ms/step - loss: 0.0036 - categorical_accuracy: 0.9993 - precision: 0.9993 - recall: 0.9992 - val_loss: 2.2388 - val_categorical_accuracy: 0.6910 - val_precision: 0.7211 - val_recall: 0.6828 - lr: 1.0000e-05\n",
      "Epoch 19/100\n",
      "3716/3716 [==============================] - 1436s 386ms/step - loss: 0.0036 - categorical_accuracy: 0.9994 - precision: 0.9995 - recall: 0.9993 - val_loss: 2.2808 - val_categorical_accuracy: 0.6931 - val_precision: 0.7212 - val_recall: 0.6840 - lr: 1.0000e-05\n",
      "Epoch 20/100\n",
      "3716/3716 [==============================] - 1435s 386ms/step - loss: 0.0034 - categorical_accuracy: 0.9994 - precision: 0.9995 - recall: 0.9994 - val_loss: 2.2995 - val_categorical_accuracy: 0.6906 - val_precision: 0.7213 - val_recall: 0.6826 - lr: 1.0000e-05\n",
      "Epoch 21/100\n",
      "3716/3716 [==============================] - 1435s 386ms/step - loss: 0.0029 - categorical_accuracy: 0.9993 - precision: 0.9994 - recall: 0.9993 - val_loss: 2.3407 - val_categorical_accuracy: 0.6919 - val_precision: 0.7197 - val_recall: 0.6847 - lr: 1.0000e-05\n",
      "Epoch 22/100\n",
      "3716/3716 [==============================] - 1436s 386ms/step - loss: 0.0025 - categorical_accuracy: 0.9995 - precision: 0.9995 - recall: 0.9994 - val_loss: 2.3555 - val_categorical_accuracy: 0.6896 - val_precision: 0.7181 - val_recall: 0.6832 - lr: 1.0000e-05\n",
      "Epoch 23/100\n",
      "3716/3716 [==============================] - 1442s 388ms/step - loss: 0.0028 - categorical_accuracy: 0.9995 - precision: 0.9995 - recall: 0.9995 - val_loss: 2.4158 - val_categorical_accuracy: 0.6893 - val_precision: 0.7174 - val_recall: 0.6819 - lr: 1.0000e-05\n",
      "Epoch 24/100\n",
      "3716/3716 [==============================] - 1442s 388ms/step - loss: 0.0021 - categorical_accuracy: 0.9997 - precision: 0.9997 - recall: 0.9996 - val_loss: 2.4380 - val_categorical_accuracy: 0.6921 - val_precision: 0.7193 - val_recall: 0.6839 - lr: 1.0000e-05\n",
      "Epoch 25/100\n",
      "3282/3716 [=========================>....] - ETA: 2:35 - loss: 0.0021 - categorical_accuracy: 0.9997 - precision: 0.9997 - recall: 0.9996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit_generator(ds_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mds_valid, callbacks\u001b[39m=\u001b[39;49m[checkpoint, early_stopping, reduce_lr])\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/engine/training.py:2636\u001b[0m, in \u001b[0;36mModel.fit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fits the model on data yielded batch-by-batch by a Python generator.\u001b[39;00m\n\u001b[1;32m   2625\u001b[0m \n\u001b[1;32m   2626\u001b[0m \u001b[39mDEPRECATED:\u001b[39;00m\n\u001b[1;32m   2627\u001b[0m \u001b[39m  `Model.fit` now supports generators, so there is no longer any need to\u001b[39;00m\n\u001b[1;32m   2628\u001b[0m \u001b[39m  use this endpoint.\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2630\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2631\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m`Model.fit_generator` is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2632\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mwill be removed in a future version. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2633\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPlease use `Model.fit`, which supports generators.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   2634\u001b[0m     stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2635\u001b[0m )\n\u001b[0;32m-> 2636\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   2637\u001b[0m     generator,\n\u001b[1;32m   2638\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   2639\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   2640\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m   2641\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   2642\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m   2643\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   2644\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m   2645\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   2646\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2647\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2648\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2649\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   2650\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   2651\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/engine/training.py:1691\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1690\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1691\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1692\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1693\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/utils/tf_utils.py:680\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    678\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/util/nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    913\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    914\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    916\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    918\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/keras/utils/tf_utils.py:673\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    671\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 673\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    674\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1160\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \n\u001b[1;32m   1139\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1157\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1159\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1160\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m/workspaces/projet_bees_detection_basile/venv_bees_detection/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1126\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1125\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1126\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1127\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(ds_train, epochs=100, validation_data=ds_valid, callbacks=[checkpoint, early_stopping, reduce_lr])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19117 files belonging to 258 classes.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m nb_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(class_names)\n\u001b[1;32m     19\u001b[0m X,y \u001b[39m=\u001b[39m load_dataset(path_test)\n\u001b[0;32m---> 21\u001b[0m X \u001b[39m=\u001b[39m path_to_tensor(X)\n",
      "Cell \u001b[0;32mIn[19], line 12\u001b[0m, in \u001b[0;36mpath_to_tensor\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpath_to_tensor\u001b[39m(img_path):\n\u001b[1;32m     11\u001b[0m     \u001b[39m# loads RGB image as PIL.Image.Image type\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     img \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mload_img(img_path, target_size\u001b[39m=\u001b[39m(\u001b[39m224\u001b[39m, \u001b[39m224\u001b[39m))\n\u001b[1;32m     13\u001b[0m     \u001b[39m# convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     x \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mimg_to_array(img)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "path_test = '../data_bees_detection/dataset_classification/test'\n",
    "\n",
    "IMG_SIZE = 224\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory=path_test,\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    shuffle = False,\n",
    "    batch_size=16,\n",
    "    image_size=(IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "nb_classes = len(class_names)\n",
    "\n",
    "\n",
    "X,y = load_dataset(path_test)\n",
    "\n",
    "X = path_to_tensor(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_weights = '../../datafiles/classification/saved_weights/benchmark_weights/1_simple_resnet.hdf5'\n",
    "model.load_weights(path_to_weights)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

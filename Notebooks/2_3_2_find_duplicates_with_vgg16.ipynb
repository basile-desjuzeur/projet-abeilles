{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <u>**Trouver les images (trop) similaires de Inaturalist grâce au réseau VGG16** </u></center>\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; justify-content: center; margin-top: 60px;\">\n",
    "    <div style=\"text-align: center; margin-right: 0px;\">\n",
    "        <img src=\"../datafiles/images/173740578.jpg\" alt=\"173740578.jpg\" style=\"width: 500px;\">\n",
    "        <p style=\"font-weight: ;\">173740578.jpg</p>\n",
    "    </div>\n",
    "    <div style=\"text-align: center; margin-left: 0px;\">\n",
    "        <img src=\"../datafiles/images/173740578.jpg\" alt=\"173740578.jpg\" style=\"width: 500px;\">\n",
    "        <p style=\"font-weight: ;\">173740578.jpg</p>\n",
    "    </div>\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contexte\n",
    "\n",
    "\n",
    "\n",
    "* Comme vu dans le Notebook précédent (./2_3_2_find_duplicates_with_vgg16.ipynb), il est judicieux de comparer uniquement les photos qui ont le même taxon_id et la même observation_id.\n",
    "\n",
    "* On va utiliser le réseau VGG16 préentrainé sur ImageNet pour extraires les features des images de Inaturalist. \n",
    "\n",
    "* On va regarder la cosine similarity entre les features des images.\n",
    "\n",
    "Idéalement, à la fin de l'expérimentation, on définira un seuil à partir duquel on considère que deux images sont similaires.\n",
    "On pourra alors supprimer les images qui sont trop similaires."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Test 3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "feature_extractor = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    try :\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "    except:\n",
    "        print(img_path)\n",
    "    img = img.reshape((1, 224, 224, 3))\n",
    "    img = keras.applications.vgg16.preprocess_input(img)\n",
    "    features = feature_extractor.predict(img)\n",
    "    return features\n",
    "\n",
    "img_1 = '../datafiles/images/173740578.jpg'\n",
    "img_2 = '../datafiles/images/173740328.jpg'\n",
    "img_3 = '../datafiles/images/perimeter.png'\n",
    "\n",
    "# 25088 features\n",
    "features_1 = extract_features(img_1).flatten()\n",
    "features_2 = extract_features(img_2).flatten()\n",
    "features_3 = extract_features(img_3).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between image 1 and image 2 (similar) : 1.00\n",
      "Cosine similarity between image 1 and image 3 (different) : 0.10\n",
      "\n",
      "\n",
      "Euclidean distance between image 1 and image 2 (similar) : 0.00\n",
      "Euclidean distance between image 1 and image 3 (different) : 1854.70\n"
     ]
    }
   ],
   "source": [
    "from keras.metrics import cosine_similarity\n",
    "import tensorflow as tf\n",
    "\n",
    "cs_1 = cosine_similarity(features_1, features_2).numpy()\n",
    "cs_2 = cosine_similarity(features_1, features_3).numpy()\n",
    "\n",
    "print('Cosine similarity between image 1 and image 2 (similar) : {:.2f}'.format(cs_1))\n",
    "print('Cosine similarity between image 1 and image 3 (different) : {:.2f}'.format(cs_2))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "de_1 = tf.norm(features_1-features_2,ord='euclidean').numpy()\n",
    "de_2 = tf.norm(features_1-features_3,ord='euclidean').numpy()\n",
    "\n",
    "print('Euclidean distance between image 1 and image 2 (similar) : {:.2f}'.format(de_1))\n",
    "print('Euclidean distance between image 1 and image 3 (different) : {:.2f}'.format(de_2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Construction et vérification de la pipeline sur un dossier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 23:45:44.679160: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-09 23:45:44.805058: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-09 23:45:47.693524: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:47.704926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:47.705072: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:47.706186: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:47.706352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:47.706473: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:48.272024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:48.272206: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:48.272306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-09 23:45:48.272401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2594 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.metrics import cosine_similarity\n",
    "\n",
    "feature_extractor = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    try :\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.reshape((1, 224, 224, 3))\n",
    "    except : \n",
    "        print('exception occured with {} while reshaping the picture'.format(img_path))\n",
    "        img = np.zeros(150528)\n",
    "        img = img.reshape((1, 224, 224, 3))\n",
    "\n",
    "\n",
    "    img = keras.applications.vgg16.preprocess_input(img)\n",
    "    features = feature_extractor.predict(img,verbose = 0)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "def compare_images(paths_to_compare):\n",
    "\n",
    "    # compute features\n",
    "    features_dict= {path:extract_features(path) for path in paths_to_compare}\n",
    "\n",
    "    # create combinations list\n",
    "    combinations = list(itertools.combinations(paths_to_compare, 2))\n",
    "\n",
    "    # compute cosines\n",
    "    cosines = {str(pair): cosine_similarity(features_dict[pair[0]],features_dict[pair[1]]).numpy().sum() for pair in combinations}\n",
    "\n",
    "    # compute euclidians \n",
    "    euclidians = {str(pair): tf.norm(features_dict[pair[0]]-features_dict[pair[1]],ord='euclidean').numpy() for pair in combinations}\n",
    "\n",
    "    # readable img names \n",
    "    img_names = {str(pair): pair[0].split('/')[-1]+' vs '+pair[1].split('/')[-1] for pair in combinations}\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame({'compared_images': img_names,'cosine_similarity': cosines, 'euclidean_distance': euclidians})\n",
    "\n",
    "    # sort by cosine similarity and euclidean distance\n",
    "    df.sort_values(by=['cosine_similarity', 'euclidean_distance'], ascending=False, inplace=True)\n",
    "\n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "paths_to_compare = os.listdir('../../data_bees_detection/test_duplicates')\n",
    "paths_to_compare = [os.path.join('../../data_bees_detection/test_duplicates',path) for path in paths_to_compare]\n",
    "\n",
    "df = compare_images(paths_to_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.181309</td>\n",
       "      <td>1992.003052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.065332</td>\n",
       "      <td>212.014236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.054448</td>\n",
       "      <td>1288.347412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.138802</td>\n",
       "      <td>1839.710327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.170699</td>\n",
       "      <td>1985.522949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.213472</td>\n",
       "      <td>2142.566162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.523685</td>\n",
       "      <td>2566.611328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cosine_similarity  euclidean_distance\n",
       "count         325.000000          325.000000\n",
       "mean            0.181309         1992.003052\n",
       "std             0.065332          212.014236\n",
       "min             0.054448         1288.347412\n",
       "25%             0.138802         1839.710327\n",
       "50%             0.170699         1985.522949\n",
       "75%             0.213472         2142.566162\n",
       "max             0.523685         2566.611328"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import et mise en forme des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>genus_species</th>\n",
       "      <th>observation_uuid</th>\n",
       "      <th>extension</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132248441</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>e29b4186-381c-4dae-92e8-61438d2ab5ea</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>198353246</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>c139e219-2436-4df6-8128-f83490a89d3f</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>212828135</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>9abe51ae-d287-403d-a5e4-7fea0382d122</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>129674943</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>bed9595c-1c70-49df-b8f9-9ca32b70e8cc</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>212828085</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>9abe51ae-d287-403d-a5e4-7fea0382d122</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>198353300</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>c139e219-2436-4df6-8128-f83490a89d3f</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>199335007</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>ce01cc40-21a9-43b0-a112-12f867f030a1</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>145388431</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>2c57d7b2-c093-4373-8e4a-1ba3a83aea91</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>198351228</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>576eb944-52dd-42d8-af63-4b1c6d2333b3</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>198351249</td>\n",
       "      <td>Hylaeus hyalinatus</td>\n",
       "      <td>576eb944-52dd-42d8-af63-4b1c6d2333b3</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     photo_id       genus_species                      observation_uuid  \\\n",
       "0   132248441  Hylaeus hyalinatus  e29b4186-381c-4dae-92e8-61438d2ab5ea   \n",
       "3   198353246  Hylaeus hyalinatus  c139e219-2436-4df6-8128-f83490a89d3f   \n",
       "4   212828135  Hylaeus hyalinatus  9abe51ae-d287-403d-a5e4-7fea0382d122   \n",
       "5   129674943  Hylaeus hyalinatus  bed9595c-1c70-49df-b8f9-9ca32b70e8cc   \n",
       "6   212828085  Hylaeus hyalinatus  9abe51ae-d287-403d-a5e4-7fea0382d122   \n",
       "7   198353300  Hylaeus hyalinatus  c139e219-2436-4df6-8128-f83490a89d3f   \n",
       "8   199335007  Hylaeus hyalinatus  ce01cc40-21a9-43b0-a112-12f867f030a1   \n",
       "9   145388431  Hylaeus hyalinatus  2c57d7b2-c093-4373-8e4a-1ba3a83aea91   \n",
       "10  198351228  Hylaeus hyalinatus  576eb944-52dd-42d8-af63-4b1c6d2333b3   \n",
       "11  198351249  Hylaeus hyalinatus  576eb944-52dd-42d8-af63-4b1c6d2333b3   \n",
       "\n",
       "   extension                                               path  \n",
       "0        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "3        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "4        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "5        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "6        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "7        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "8       jpeg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "9        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "10       jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "11       jpg  ../../data_bees_detection/whole_dataset/inatur...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../../data_bees_detection/inat_utils/inaturalist_2305_observation_uuid.csv')\n",
    "\n",
    "# keep only rows were concatenate is not unique\n",
    "df = df[df['observation_uuid'].duplicated(keep=False)]\n",
    "\n",
    "df['path'] = df.apply(lambda x: os.path.join('../../data_bees_detection/whole_dataset/inaturalist_2305',x['genus_species'],str(x['photo_id'])+'.'+x['extension']), axis=1)\n",
    "\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of uuids : 42058\n",
      "number of feature vectors to compute : 140172\n",
      "number of comparisons to make : 245810\n"
     ]
    }
   ],
   "source": [
    "# count number of iterations\n",
    "import itertools\n",
    "\n",
    "uuids = df['observation_uuid'].unique()\n",
    "print('number of uuids : {}'.format(len(uuids)))\n",
    "\n",
    "photos_per_uuid = df['observation_uuid'].value_counts()\n",
    "sum_photos = photos_per_uuid.sum()\n",
    "print('number of feature vectors to compute : {}'.format(sum_photos))\n",
    "\n",
    "\n",
    "comparisons_per_uuid = [itertools.combinations(range(uuid),2) for uuid in photos_per_uuid]\n",
    "\n",
    "nb_comparisons_per_uuid = [sum(1 for iter in iterable) for iterable in comparisons_per_uuid]\n",
    "sum_comparisons = sum(nb_comparisons_per_uuid)\n",
    "print('number of comparisons to make : {}'.format(sum_comparisons))\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Définition d'un premier seuil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Approche naïve : afficher des échantillons d'images similaires sous différents seuils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_uuids = df['observation_uuid'].unique()\n",
    "\n",
    "# take 500 random uuid\n",
    "observation_uuids = np.random.choice(observation_uuids,1000)\n",
    "\n",
    "# get correponding paths\n",
    "paths = [df[df['observation_uuid'] == id]['path'] for id in observation_uuids]\n",
    "\n",
    "# compare paths\n",
    "dfs_comparisons = [compare_images(path_list) for path_list in paths]\n",
    "\n",
    "final_df = pd.concat(dfs_comparisons)\n",
    "\n",
    "final_df.to_csv('../datafiles/scrap_inat/duplicates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "def save_duplicate(img_1_path,img_2_path,cosine_similarity,euclidean_distance,plot=False):\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 10))\n",
    "\n",
    "    img_1 = cv2.imread(img_1_path, cv2.IMREAD_COLOR)\n",
    "    img_2 = cv2.imread(img_2_path, cv2.IMREAD_COLOR)    \n",
    "\n",
    "    img_1_rgb = cv2.cvtColor(img_1, cv2.COLOR_BGR2RGB)\n",
    "    img_2_rgb = cv2.cvtColor(img_2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    axs[0].imshow(img_1_rgb)\n",
    "    axs[1].imshow(img_2_rgb)\n",
    "    \n",
    "    img_1_name , img_2_name = img_1_path.split('/')[-1].split('.')[0], img_2_path.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    axs[0].set_title('Image 1: {}'.format(img_1_name))\n",
    "    axs[1].set_title('Image 2 : {}'.format(img_2_name))\n",
    "\n",
    "    fig.suptitle('Cosine similarity: {:.2f}, Euclidean distance: {:.2f}'.format(cosine_similarity, euclidean_distance))\n",
    "\n",
    "    # save image\n",
    "    plt.savefig('../datafiles/scrap_inat/duplicates/{}vs{}.png'.format(img_1_name,img_2_name))\n",
    "\n",
    "    if plot != False:\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the dataframe\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# RECUPERATION DU TAXON POUR POUVOIR FAIRE DES STATISTIQUES PAR ESPECES\n",
    "\n",
    "\n",
    "# Load the data\n",
    "df_duplicates = pd.read_csv('../datafiles/scrap_inat/duplicates.csv',index_col=0)\n",
    "\n",
    "df_duplicates['image_1'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[0])\n",
    "df_duplicates['image_2'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[-1])\n",
    "df_duplicates['photo_id'] = df_duplicates['image_1'].apply(lambda x : x.split('.')[0]).astype(int)\n",
    "\n",
    "\n",
    "# join with inat dataset\n",
    "df_inat = pd.read_csv('../../data_bees_detection/inat_utils/inaturalist_2305.csv')\n",
    "\n",
    "# set indexes\n",
    "df_duplicates = df_duplicates.merge(df_inat,left_on=['photo_id'],right_on=['photo_id'],how ='left')\n",
    "\n",
    "#drop comared_images column\n",
    "df_duplicates.drop('compared_images',axis=1,inplace=True)\n",
    "\n",
    "base_path = '../../data_bees_detection/whole_dataset/inaturalist_2305/'\n",
    "\n",
    "\n",
    "# shuffle the dataframe\n",
    "df_duplicates = df_duplicates.sample(frac=1)\n",
    "\n",
    "counter = 0\n",
    "for index, row in df_duplicates.iterrows():\n",
    "    if counter < 10:\n",
    "        \n",
    "        img_1, img_2 = row['image_1'], row['image_2']\n",
    "        label = row['genus_species']\n",
    "\n",
    "        img_1_path , img_2_path = os.path.join(base_path,label,img_1), os.path.join(base_path,label,img_2)\n",
    "\n",
    "\n",
    "        cosine_similarity, euclidean_distance = row['cosine_similarity'], row['euclidean_distance']\n",
    "\n",
    "        save_duplicate(img_1_path,img_2_path,cosine_similarity,euclidean_distance,plot=False)\n",
    "\n",
    "        print('Image 1: {}, Image 2: {}, Cosine similarity: {:.2f}, Euclidean distance: {:.2f}'.format(img_1_path,img_2_path,cosine_similarity, euclidean_distance))\n",
    "        \n",
    "        counter += 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Approche  statistique : influence du seuil sur le nombre d'images similaires"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prédictions sur une partie du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "observation_uuids = df['observation_uuid'].unique()\n",
    "\n",
    "\n",
    "# split uuids in 100 batches\n",
    "observation_uuids_batches = np.array_split(observation_uuids, 100)\n",
    "\n",
    "for i, batch in enumerate(observation_uuids_batches):\n",
    "\n",
    "    # get correponding paths\n",
    "    paths = [df[df['observation_uuid'] == id]['path'] for id in batch]\n",
    "\n",
    "    # compare paths\n",
    "    dfs_comparisons = [compare_images(path_list) for path_list in paths]\n",
    "\n",
    "    final_df = pd.concat(dfs_comparisons)\n",
    "    final_df.to_csv('../datafiles/scrap_inat/to_merge/duplicates_{}.csv'.format(i))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(On comptait faire sur tout le dataset mais ça prend trop de temps, le code précédent pourrait suffire pour prédire sur tout le dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of comparisons already computed : 72404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>72404.000000</td>\n",
       "      <td>72404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.341891</td>\n",
       "      <td>1599.952511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.167263</td>\n",
       "      <td>456.821912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.223082</td>\n",
       "      <td>1295.725900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.303290</td>\n",
       "      <td>1615.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.420530</td>\n",
       "      <td>1915.519050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3399.182000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cosine_similarity  euclidean_distance\n",
       "count       72404.000000        72404.000000\n",
       "mean            0.341891         1599.952511\n",
       "std             0.167263          456.821912\n",
       "min             0.015183            0.000000\n",
       "25%             0.223082         1295.725900\n",
       "50%             0.303290         1615.838400\n",
       "75%             0.420530         1915.519050\n",
       "max             1.000000         3399.182000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of already computed comparisons\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "path = '../datafiles/scrap_inat/to_merge/duplicates_*.csv'\n",
    "all_files = glob.glob(path)\n",
    "\n",
    "nb = 0\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename,index_col=0,header=0)\n",
    "    nb += df.shape[0]\n",
    "    li.append(df)\n",
    "\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=False)\n",
    "\n",
    "frame.to_csv('../datafiles/scrap_inat/duplicates_0710.csv',index=False)\n",
    "print('number of comparisons already computed : {}'.format(nb))\n",
    "\n",
    "frame.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des labels pour pouvoir avoir une idée de l'imact du seuil par espèce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.318352</td>\n",
       "      <td>1631.177934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.096663</td>\n",
       "      <td>279.714303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.123936</td>\n",
       "      <td>799.452640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.265161</td>\n",
       "      <td>1516.869688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.310879</td>\n",
       "      <td>1617.960725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.346382</td>\n",
       "      <td>1800.772725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.667839</td>\n",
       "      <td>2336.421650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cosine_similarity  euclidean_distance\n",
       "count          80.000000           80.000000\n",
       "mean            0.318352         1631.177934\n",
       "std             0.096663          279.714303\n",
       "min             0.123936          799.452640\n",
       "25%             0.265161         1516.869688\n",
       "50%             0.310879         1617.960725\n",
       "75%             0.346382         1800.772725\n",
       "max             0.667839         2336.421650"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the data\n",
    "df_duplicates = pd.read_csv('../datafiles/scrap_inat/duplicates_0710.csv',index_col=None)\n",
    "\n",
    "df_duplicates['image_1'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[0])\n",
    "df_duplicates['image_2'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[-1])\n",
    "df_duplicates['photo_id'] = df_duplicates['image_1'].apply(lambda x : x.split('.')[0]).astype(int)\n",
    "\n",
    "\n",
    "# join with inat dataset\n",
    "df_inat = pd.read_csv('../../data_bees_detection/inat_utils/inaturalist_2305.csv')\n",
    "\n",
    "# set indexes\n",
    "df_duplicates = df_duplicates.merge(df_inat,left_on=['photo_id'],right_on=['photo_id'],how ='left')\n",
    "\n",
    "#drop comared_images column\n",
    "df_duplicates.drop(['image_1','image_2','photo_id','compared_images'],inplace=True,axis=1)\n",
    "\n",
    "df_duplicates.groupby(['genus_species']).quantile(0.5).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>genus_species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.286500</td>\n",
       "      <td>1741.91280</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.448318</td>\n",
       "      <td>1731.69340</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.336898</td>\n",
       "      <td>2034.01640</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.308329</td>\n",
       "      <td>1750.44790</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.269743</td>\n",
       "      <td>1404.17700</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72399</th>\n",
       "      <td>0.935105</td>\n",
       "      <td>571.19135</td>\n",
       "      <td>Osmia bicornis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72400</th>\n",
       "      <td>0.552981</td>\n",
       "      <td>1645.89990</td>\n",
       "      <td>Osmia bicornis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72401</th>\n",
       "      <td>0.217821</td>\n",
       "      <td>2136.90230</td>\n",
       "      <td>Osmia bicornis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72402</th>\n",
       "      <td>0.502273</td>\n",
       "      <td>1210.88850</td>\n",
       "      <td>Osmia bicornis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72403</th>\n",
       "      <td>0.576897</td>\n",
       "      <td>1715.08200</td>\n",
       "      <td>Osmia bicornis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72404 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cosine_similarity  euclidean_distance        genus_species\n",
       "0               0.286500          1741.91280  Anthidium manicatum\n",
       "1               0.448318          1731.69340  Anthidium manicatum\n",
       "2               0.336898          2034.01640  Anthidium manicatum\n",
       "3               0.308329          1750.44790  Anthidium manicatum\n",
       "4               0.269743          1404.17700  Anthidium manicatum\n",
       "...                  ...                 ...                  ...\n",
       "72399           0.935105           571.19135       Osmia bicornis\n",
       "72400           0.552981          1645.89990       Osmia bicornis\n",
       "72401           0.217821          2136.90230       Osmia bicornis\n",
       "72402           0.502273          1210.88850       Osmia bicornis\n",
       "72403           0.576897          1715.08200       Osmia bicornis\n",
       "\n",
       "[72404 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_thresholds = np.linspace(0.2,1,0.1)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En première approche : on peut ne garder que ceux dont la cosine similarity est supérieure à 0.4 pour désengorger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Filtre avec ce premier seuil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Code final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10 22:24:51.637800: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-10 22:24:51.764315: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-10 22:24:55.107883: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.123044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.123261: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.124544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.124730: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.124849: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.677845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.678257: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.678560: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-10 22:24:55.678822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2594 MB memory:  -> device: 0, name: NVIDIA T600 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.metrics import cosine_similarity\n",
    "\n",
    "feature_extractor = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "\n",
    "def extract_features(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    try :\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = img.reshape((1, 224, 224, 3))\n",
    "    except : \n",
    "        print('exception occured with {} while reshaping the picture'.format(img_path))\n",
    "        img = np.zeros(150528)\n",
    "        img = img.reshape((1, 224, 224, 3))\n",
    "\n",
    "\n",
    "    img = keras.applications.vgg16.preprocess_input(img)\n",
    "    features = feature_extractor.predict(img,verbose = 0)\n",
    "    return features.flatten()\n",
    "\n",
    "\n",
    "def compare_images(paths_to_compare,cosine_threshold =0.4):\n",
    "\n",
    "    # compute features\n",
    "    features_dict= {path:extract_features(path) for path in paths_to_compare}\n",
    "\n",
    "    # create combinations list\n",
    "    combinations = list(itertools.combinations(paths_to_compare, 2))\n",
    "\n",
    "    # compute cosines\n",
    "    cosines = {str(pair): cosine_similarity(features_dict[pair[0]],features_dict[pair[1]]).numpy().sum() for pair in combinations}\n",
    "\n",
    "    # compute euclidians \n",
    "    euclidians = {str(pair): tf.norm(features_dict[pair[0]]-features_dict[pair[1]],ord='euclidean').numpy() for pair in combinations}\n",
    "\n",
    "    # readable img names \n",
    "    img_names = {str(pair): pair[0].split('/')[-1]+' vs '+pair[1].split('/')[-1] for pair in combinations}\n",
    "\n",
    "    # create dataframe\n",
    "    df = pd.DataFrame({'compared_images': img_names,'cosine_similarity': cosines, 'euclidean_distance': euclidians})\n",
    "\n",
    "    # filter dataframe\n",
    "    df_filtered = df[df['cosine_similarity']>cosine_threshold].copy()\n",
    "\n",
    "    # sort by cosine similarity and euclidean distance\n",
    "    df_filtered.sort_values(by=['cosine_similarity', 'euclidean_distance'], ascending=False, inplace=True)\n",
    "\n",
    "    # reset index\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_filtered\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('../../data_bees_detection/inat_utils/inaturalist_2305_observation_uuid.csv')\n",
    "\n",
    "# keep only rows were concatenate is not unique\n",
    "df = df[df['observation_uuid'].duplicated(keep=False)]\n",
    "\n",
    "df['path'] = df.apply(lambda x: os.path.join('../../data_bees_detection/whole_dataset/inaturalist_2305',x['genus_species'],str(x['photo_id'])+'.'+x['extension']), axis=1)\n",
    "\n",
    "# on ne prédit pas ceux ui ont déja été prédits\n",
    "df_predicted = pd.read_csv('../datafiles/scrap_inat/biggest_duplicates.csv')\n",
    "df_predicted['image_1'] = df_predicted['compared_images'].apply(lambda x: x.split(' ')[0].split('.')[0]).astype(int)\n",
    "df_predicted['image_2'] = df_predicted['compared_images'].apply(lambda x: x.split(' ')[-1].split('.')[0]).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask indicating whether each value in photo_id is present in photo_predicted\n",
    "mask = df['photo_id'].isin(df_predicted['image_1'])\n",
    "\n",
    "# Filter rows where photo_id is not present in photo_predicted\n",
    "df_filtered = df[~mask]\n",
    "\n",
    "# Create a boolean mask indicating whether each value in photo_id is present in photo_predicted\n",
    "mask = df['photo_id'].isin(df_predicted['image_2'])\n",
    "\n",
    "# Filter rows where photo_id is not present in photo_predicted\n",
    "df_filtered = df[~mask]\n",
    "\n",
    "# keep only rows were concatenate is not unique\n",
    "df_filtered = df_filtered[df_filtered['observation_uuid'].duplicated(keep=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>photo_id</th>\n",
       "      <th>genus_species</th>\n",
       "      <th>observation_uuid</th>\n",
       "      <th>extension</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43217</th>\n",
       "      <td>239605746</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "      <td>21086320-9536-42f4-9456-6982cd4b5fe7</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43218</th>\n",
       "      <td>237055751</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "      <td>7ff53329-be36-4b12-8d02-85c9fc6b47be</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43221</th>\n",
       "      <td>4239494</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "      <td>84039afc-e2ea-45e3-a35f-7a597828ac3d</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43223</th>\n",
       "      <td>207758917</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "      <td>22aaa8d1-32ea-4bc0-8225-abd54f2b761a</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43225</th>\n",
       "      <td>20476871</td>\n",
       "      <td>Anthidium manicatum</td>\n",
       "      <td>633d3f3d-cfbb-44d0-ae3f-58c075218f0d</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178755</th>\n",
       "      <td>145103301</td>\n",
       "      <td>Megachile albisecta</td>\n",
       "      <td>dfb73991-fd60-4dab-b847-4a191670d785</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178758</th>\n",
       "      <td>89133683</td>\n",
       "      <td>Megachile albisecta</td>\n",
       "      <td>2596ad92-b4f1-43bf-a292-293d07deea3d</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178765</th>\n",
       "      <td>52581492</td>\n",
       "      <td>Megachile albisecta</td>\n",
       "      <td>3eca66fd-06b0-4e3e-a41a-a1aa3dab24d2</td>\n",
       "      <td>jpeg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178774</th>\n",
       "      <td>89133727</td>\n",
       "      <td>Megachile albisecta</td>\n",
       "      <td>2596ad92-b4f1-43bf-a292-293d07deea3d</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178777</th>\n",
       "      <td>217109189</td>\n",
       "      <td>Megachile albisecta</td>\n",
       "      <td>ddfe1770-06e3-431e-b27e-25ad0d208e6a</td>\n",
       "      <td>jpg</td>\n",
       "      <td>../../data_bees_detection/whole_dataset/inatur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60870 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         photo_id        genus_species                      observation_uuid  \\\n",
       "43217   239605746  Anthidium manicatum  21086320-9536-42f4-9456-6982cd4b5fe7   \n",
       "43218   237055751  Anthidium manicatum  7ff53329-be36-4b12-8d02-85c9fc6b47be   \n",
       "43221     4239494  Anthidium manicatum  84039afc-e2ea-45e3-a35f-7a597828ac3d   \n",
       "43223   207758917  Anthidium manicatum  22aaa8d1-32ea-4bc0-8225-abd54f2b761a   \n",
       "43225    20476871  Anthidium manicatum  633d3f3d-cfbb-44d0-ae3f-58c075218f0d   \n",
       "...           ...                  ...                                   ...   \n",
       "178755  145103301  Megachile albisecta  dfb73991-fd60-4dab-b847-4a191670d785   \n",
       "178758   89133683  Megachile albisecta  2596ad92-b4f1-43bf-a292-293d07deea3d   \n",
       "178765   52581492  Megachile albisecta  3eca66fd-06b0-4e3e-a41a-a1aa3dab24d2   \n",
       "178774   89133727  Megachile albisecta  2596ad92-b4f1-43bf-a292-293d07deea3d   \n",
       "178777  217109189  Megachile albisecta  ddfe1770-06e3-431e-b27e-25ad0d208e6a   \n",
       "\n",
       "       extension                                               path  \n",
       "43217       jpeg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "43218        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "43221        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "43223        jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "43225       jpeg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "...          ...                                                ...  \n",
       "178755      jpeg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "178758       jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "178765      jpeg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "178774       jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "178777       jpg  ../../data_bees_detection/whole_dataset/inatur...  \n",
       "\n",
       "[60870 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = df_filtered.copy()\n",
    "\n",
    "\n",
    "observation_uuids = df['observation_uuid'].unique()\n",
    "\n",
    "# split uuids in 100 batches\n",
    "observation_uuids_batches = np.array_split(observation_uuids,50)\n",
    "\n",
    "# shuffle batches\n",
    "np.random.shuffle(observation_uuids_batches)\n",
    "\n",
    "\n",
    "\n",
    "for i, batch in enumerate(observation_uuids_batches):\n",
    "\n",
    "    # get correponding paths\n",
    "    paths = [df[df['observation_uuid'] == id]['path'] for id in batch]\n",
    "\n",
    "    # compare paths\n",
    "    dfs_comparisons = [compare_images(path_list,cosine_threshold=0.5)for path_list in paths]\n",
    "    \n",
    "    final_df = pd.concat(dfs_comparisons)\n",
    "    final_df.to_csv('../datafiles/scrap_inat/to_merge_11/duplicates_{}.csv'.format(i))\n",
    "\n",
    "    print('batch {} done'.format(i))\n",
    "\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Filtre du dataset entier (pas implémenté)\n",
    "\n",
    "On fixe le seuil à 0.5, i.e. on ne garde que les images dont la cosine similarity est supérieure à 0.5.\n",
    "\n",
    "Arbitrairement, entre deux images on garde la première.\n",
    "\n",
    "On teste un filtre à petite mailles : on ne garde qu'un seul exemplaire d'une série de doublons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = pd.read_csv('../datafiles/scrap_inat/final_duplicates',index_col=0)\n",
    "\n",
    "df_duplicates['image_1'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[0])\n",
    "df_duplicates['image_2'] = df_duplicates['compared_images'].apply(lambda x: x.split(' ')[-1])\n",
    "\n",
    "\n",
    "# keep only comparisons with cosine similarity > 0.5\n",
    "df_duplicates = df_duplicates[df_duplicates['cosine_similarity']>0.5]\n",
    "\n",
    "\n",
    "to_remove = df_duplicates['image_2']\n",
    "\n",
    "to_keep = df_duplicates[~df['image_1'].isin(to_remove)]['image_1']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_bees_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
